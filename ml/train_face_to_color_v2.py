"""
ì–¼êµ´ íŠ¹ì§•ê³¼ ëœë¤ ì‹œë“œë¥¼ í™œìš©í•œ í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸ ìƒì„±
148ì°¨ì› ì…ë ¥ (descriptor 128 + ë¬¼ë¦¬ì  íŠ¹ì§• 15 + ëœë¤ ì‹œë“œ 5) â†’ 15ì°¨ì› RGB ì¶œë ¥
"""

import json
import numpy as np
import tensorflow as tf
from tensorflow import keras
import os
import random

def hex_to_rgb_normalized(hex_color):
    """16ì§„ìˆ˜ ìƒ‰ìƒì„ 0-1 ë²”ìœ„ì˜ RGB ê°’ìœ¼ë¡œ ë³€í™˜"""
    hex_color = hex_color.lstrip('#')
    r = int(hex_color[0:2], 16) / 255.0
    g = int(hex_color[2:4], 16) / 255.0
    b = int(hex_color[4:6], 16) / 255.0
    return [r, g, b]

def load_emotion_color_mapping():
    """ê°ì •-ìƒ‰ìƒ ë§¤í•‘ ë°ì´í„° ë¡œë“œ"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    mapping_path = os.path.join(script_dir, "..", "public", "data", "emotion-color-mapping.json")
    mapping_path = os.path.normpath(mapping_path)
    
    with open(mapping_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def generate_enhanced_face_data(emotion_mapping, num_samples_per_emotion=30):
    """í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ë°ì´í„° ìƒì„± (148ì°¨ì› ì…ë ¥)"""
    X = []  # 148ì°¨ì› ì…ë ¥ ë²¡í„° (descriptor 128 + íŠ¹ì§• 15 + ëœë¤ 5)
    y = []  # 15ì°¨ì› RGB ë²¡í„° (5ê°œ ìƒ‰ìƒ Ã— 3ê°œ RGB)
    emotions = []  # ê°ì • ë¼ë²¨
    
    for emotion_name, emotion_data in emotion_mapping['emotions'].items():
        print(f"ğŸ“Š {emotion_data['name']} ê°ì • ë°ì´í„° ìƒì„± ì¤‘...")
        
        for i in range(num_samples_per_emotion):
            # 1. 128ì°¨ì› ì–¼êµ´ descriptor ìƒì„± (ê¸°ì¡´ ë°©ì‹)
            face_descriptor = generate_emotion_based_face_vector(emotion_name, emotion_data)
            
            # 2. 15ì°¨ì› ë¬¼ë¦¬ì  íŠ¹ì§• ìƒì„± (ê°ì •ì— ë”°ë¥¸ ì–¼êµ´ íŠ¹ì§•)
            physical_features = generate_emotion_based_physical_features(emotion_name, emotion_data)
            
            # 3. 5ì°¨ì› ëœë¤ ì‹œë“œ ìƒì„±
            random_seed = [random.random() for _ in range(5)]
            
            # 4. 148ì°¨ì› ì…ë ¥ ë²¡í„° ì¡°í•©
            combined_input = np.concatenate([face_descriptor, physical_features, random_seed])
            
            # 5. ê°ì •ì— ë§ëŠ” ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„ íƒ
            base_palette = random.choice(emotion_data['basePalettes'])
            
            # 6. ìƒ‰ìƒ íŒ”ë ˆíŠ¸ë¥¼ 15ì°¨ì› RGB ë²¡í„°ë¡œ ë³€í™˜
            rgb_vector = []
            for color in base_palette:
                rgb = hex_to_rgb_normalized(color)
                rgb_vector.extend(rgb)
            
            # 7. ìƒ‰ìƒ ë²¡í„°ì— ë¬¼ë¦¬ì  íŠ¹ì§•ê³¼ ëœë¤ ì‹œë“œì— ë”°ë¥¸ ë³€í˜• ì¶”ê°€
            rgb_vector = add_enhanced_color_variation(
                rgb_vector, 
                physical_features, 
                random_seed,
                emotion_data['colorCharacteristics']
            )
            
            X.append(combined_input)
            y.append(rgb_vector)
            emotions.append(emotion_name)
    
    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32), emotions

def generate_emotion_based_face_vector(emotion_name, emotion_data):
    """ê°ì •ì— ë”°ë¥¸ ì–¼êµ´ descriptor ìƒì„± (ê¸°ì¡´ ë°©ì‹)"""
    # ê¸°ë³¸ 128ì°¨ì› ë²¡í„° (ì •ê·œë¶„í¬)
    face_vector = np.random.normal(0, 1, 128)
    
    # ê°ì •ë³„ íŠ¹ì„± ë°˜ì˜
    char = emotion_data['colorCharacteristics']
    
    if emotion_name == 'happy':
        # í–‰ë³µ: ë°ê³  í™œê¸°ì°¬ íŠ¹ì§• (ì–‘ìˆ˜ í¸í–¥)
        face_vector = np.abs(face_vector) * 0.8 + 0.2
    elif emotion_name == 'sad':
        # ìŠ¬í””: ì–´ë‘¡ê³  ì°¨ë¶„í•œ íŠ¹ì§• (ìŒìˆ˜ í¸í–¥)
        face_vector = -np.abs(face_vector) * 0.6 - 0.1
    elif emotion_name == 'angry':
        # ë¶„ë…¸: ê°•ë ¬í•˜ê³  ëŒ€ë¹„ ë†’ì€ íŠ¹ì§• (ê·¹ê°’)
        face_vector = np.sign(face_vector) * np.power(np.abs(face_vector), 0.5)
    elif emotion_name == 'fearful':
        # ë‘ë ¤ì›€: ì°¨ê°€ìš´ íŠ¹ì§• (íŠ¹ì • ì°¨ì› ê°•ì¡°)
        face_vector[0:32] *= 1.5  # ì•ìª½ ì°¨ì› ê°•ì¡°
    elif emotion_name == 'disgusted':
        # í˜ì˜¤: íƒí•œ íŠ¹ì§• (ì¤‘ê°„ê°’ ì¤‘ì‹¬)
        face_vector = np.tanh(face_vector) * 0.5
    elif emotion_name == 'surprised':
        # ë†€ëŒ: ì„ ëª…í•œ íŠ¹ì§• (ê³ ì£¼íŒŒ ì„±ë¶„)
        face_vector = face_vector * np.sin(np.linspace(0, 4*np.pi, 128))
    else:  # neutral
        # ì¤‘ë¦½: ê· í˜• ì¡íŒ íŠ¹ì§• (ì •ê·œë¶„í¬ ìœ ì§€)
        pass
    
    # ì •ê·œí™”
    face_vector = (face_vector - np.mean(face_vector)) / (np.std(face_vector) + 1e-8)
    
    return face_vector

def generate_emotion_based_physical_features(emotion_name, emotion_data):
    """ê°ì •ì— ë”°ë¥¸ ë¬¼ë¦¬ì  íŠ¹ì§• ìƒì„± (15ì°¨ì›)"""
    # ê¸°ë³¸ 15ì°¨ì› íŠ¹ì§• ë²¡í„° (0-1 ë²”ìœ„)
    features = np.random.uniform(0, 1, 15)
    
    # ê°ì •ë³„ ë¬¼ë¦¬ì  íŠ¹ì§• íŒ¨í„´ ì ìš©
    if emotion_name == 'happy':
        # í–‰ë³µ: í° ëˆˆ, ë„“ì€ ì…, ë†’ì€ ì´ë§ˆ
        features[0] = np.random.uniform(0.6, 1.0)  # ì–¼êµ´ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ (ë‘¥ê·¼ ì–¼êµ´)
        features[4] = np.random.uniform(0.7, 1.0)  # ëˆˆ í¬ê¸° (í° ëˆˆ)
        features[8] = np.random.uniform(0.7, 1.0)  # ì… ë„ˆë¹„ (ë„“ì€ ì…)
        features[2] = np.random.uniform(0.6, 1.0)  # ì´ë§ˆ ë„ˆë¹„ (ë„“ì€ ì´ë§ˆ)
        
    elif emotion_name == 'sad':
        # ìŠ¬í””: ì‘ì€ ëˆˆ, ì‘ì€ ì…, ë‚®ì€ ì´ë§ˆ
        features[0] = np.random.uniform(0.3, 0.7)  # ì–¼êµ´ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ (ê¸´ ì–¼êµ´)
        features[4] = np.random.uniform(0.2, 0.6)  # ëˆˆ í¬ê¸° (ì‘ì€ ëˆˆ)
        features[8] = np.random.uniform(0.2, 0.5)  # ì… ë„ˆë¹„ (ì‘ì€ ì…)
        features[2] = np.random.uniform(0.2, 0.6)  # ì´ë§ˆ ë„ˆë¹„ (ì¢ì€ ì´ë§ˆ)
        
    elif emotion_name == 'angry':
        # ë¶„ë…¸: ê°€ëŠ˜ê³  ê¸´ ì–¼êµ´, ì‘ì€ ëˆˆ, í° ì…
        features[0] = np.random.uniform(0.2, 0.5)  # ì–¼êµ´ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ (ê¸´ ì–¼êµ´)
        features[4] = np.random.uniform(0.3, 0.7)  # ëˆˆ í¬ê¸° (ì¤‘ê°„)
        features[8] = np.random.uniform(0.6, 1.0)  # ì… ë„ˆë¹„ (í° ì…)
        features[1] = np.random.uniform(0.6, 1.0)  # í„±ì„  ê°ë„ (ê°ì§„ í„±)
        
    elif emotion_name == 'fearful':
        # ë‘ë ¤ì›€: í° ëˆˆ, ì‘ì€ ì…, ì¢ì€ ì–¼êµ´
        features[0] = np.random.uniform(0.3, 0.6)  # ì–¼êµ´ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ (ì¢ì€ ì–¼êµ´)
        features[4] = np.random.uniform(0.7, 1.0)  # ëˆˆ í¬ê¸° (í° ëˆˆ)
        features[8] = np.random.uniform(0.2, 0.5)  # ì… ë„ˆë¹„ (ì‘ì€ ì…)
        features[5] = np.random.uniform(0.6, 1.0)  # ëˆˆê°„ ê±°ë¦¬ (ë„“ì€ ê°„ê²©)
        
    elif emotion_name == 'disgusted':
        # í˜ì˜¤: ì‘ì€ ëˆˆ, ì‘ì€ ì…, ì¢ì€ ì½”
        features[4] = np.random.uniform(0.2, 0.5)  # ëˆˆ í¬ê¸° (ì‘ì€ ëˆˆ)
        features[8] = np.random.uniform(0.2, 0.4)  # ì… ë„ˆë¹„ (ì‘ì€ ì…)
        features[12] = np.random.uniform(0.2, 0.5)  # ì½” ë„ˆë¹„ (ì¢ì€ ì½”)
        
    elif emotion_name == 'surprised':
        # ë†€ëŒ: ë§¤ìš° í° ëˆˆ, í° ì…, ë„“ì€ ì–¼êµ´
        features[0] = np.random.uniform(0.6, 1.0)  # ì–¼êµ´ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ (ë‘¥ê·¼ ì–¼êµ´)
        features[4] = np.random.uniform(0.8, 1.0)  # ëˆˆ í¬ê¸° (ë§¤ìš° í° ëˆˆ)
        features[8] = np.random.uniform(0.7, 1.0)  # ì… ë„ˆë¹„ (í° ì…)
        features[6] = np.random.uniform(0.7, 1.0)  # ëˆˆ ë†’ì´ (ë†’ì€ ëˆˆ)
        
    else:  # neutral
        # ì¤‘ë¦½: ê· í˜• ì¡íŒ íŠ¹ì§•
        features = np.random.uniform(0.3, 0.7, 15)
    
    return features

def add_enhanced_color_variation(rgb_vector, physical_features, random_seed, color_characteristics):
    """ë¬¼ë¦¬ì  íŠ¹ì§•ê³¼ ëœë¤ ì‹œë“œë¥¼ í™œìš©í•œ ìƒ‰ìƒ ë³€í˜•"""
    rgb_vector = np.array(rgb_vector)
    
    # ê¸°ë³¸ ìƒ‰ìƒ íŠ¹ì„±
    brightness = color_characteristics['brightness']
    saturation = color_characteristics['saturation']
    temperature = color_characteristics['temperature']
    
    # ë¬¼ë¦¬ì  íŠ¹ì§•ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì •
    face_ratio = physical_features[0]  # ì–¼êµ´ ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨
    eye_size = physical_features[4]    # ëˆˆ í¬ê¸°
    mouth_width = physical_features[8] # ì… ë„ˆë¹„
    
    # ëœë¤ ì‹œë“œì— ë”°ë¥¸ ë³€í˜•
    random_brightness = random_seed[0] * 0.3 - 0.15  # -0.15 ~ +0.15
    random_saturation = random_seed[1] * 0.4 - 0.2   # -0.2 ~ +0.2
    random_temperature = random_seed[2] * 0.4 - 0.2  # -0.2 ~ +0.2
    
    # ë¬¼ë¦¬ì  íŠ¹ì§•ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì •
    # í° ëˆˆ â†’ ë” ì„ ëª…í•œ ìƒ‰ìƒ
    eye_enhancement = (eye_size - 0.5) * 0.2
    # ë„“ì€ ì… â†’ ë” ë”°ëœ»í•œ ìƒ‰ìƒ
    mouth_warmth = (mouth_width - 0.5) * 0.1
    # ë‘¥ê·¼ ì–¼êµ´ â†’ ë” ë¶€ë“œëŸ¬ìš´ ìƒ‰ìƒ
    face_softness = (face_ratio - 0.5) * 0.1
    
    # ìµœì¢… ìƒ‰ìƒ ì¡°ì • ì ìš©
    for i in range(0, len(rgb_vector), 3):
        r, g, b = rgb_vector[i:i+3]
        
        # ë°ê¸° ì¡°ì • (ê¸°ë³¸ + ëœë¤ + ë¬¼ë¦¬ì  íŠ¹ì§•)
        brightness_factor = brightness + random_brightness + eye_enhancement
        rgb_vector[i:i+3] = rgb_vector[i:i+3] * brightness_factor + (1 - brightness_factor) * 0.1
        
        # ì±„ë„ ì¡°ì •
        saturation_factor = saturation + random_saturation + eye_enhancement
        max_val = max(r, g, b)
        if max_val > 0:
            rgb_vector[i:i+3] = rgb_vector[i:i+3] * saturation_factor + (1 - saturation_factor) * max_val
        
        # ìƒ‰ì˜¨ë„ ì¡°ì • (ê¸°ë³¸ + ëœë¤ + ì… íŠ¹ì§•)
        temperature_factor = temperature + random_temperature + mouth_warmth
        if temperature_factor > 0:  # ë”°ëœ»í•œ ìƒ‰
            rgb_vector[i] += temperature_factor * 0.1
            rgb_vector[i+1] += temperature_factor * 0.05
            rgb_vector[i+2] -= temperature_factor * 0.1
        else:  # ì°¨ê°€ìš´ ìƒ‰
            rgb_vector[i] -= abs(temperature_factor) * 0.1
            rgb_vector[i+1] -= abs(temperature_factor) * 0.05
            rgb_vector[i+2] += abs(temperature_factor) * 0.1
        
        # ë¶€ë“œëŸ¬ì›€ ì¡°ì • (ë‘¥ê·¼ ì–¼êµ´)
        if face_softness > 0:
            rgb_vector[i:i+3] = rgb_vector[i:i+3] * (1 - face_softness * 0.1) + face_softness * 0.1
    
    # 0-1 ë²”ìœ„ë¡œ í´ë¦¬í•‘
    rgb_vector = np.clip(rgb_vector, 0, 1)
    
    return rgb_vector.tolist()

def augment_enhanced_face_data(X, y, augmentation_factor=5):
    """í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ë°ì´í„° ì¦ê°•"""
    X_augmented = []
    y_augmented = []
    
    for i in range(len(X)):
        # ì›ë³¸ ë°ì´í„° ì¶”ê°€
        X_augmented.append(X[i])
        y_augmented.append(y[i])
        
        # ì¦ê°• ë°ì´í„° ìƒì„±
        for _ in range(augmentation_factor):
            # ê° ë¶€ë¶„ë³„ë¡œ ë‹¤ë¥¸ ë…¸ì´ì¦ˆ ì ìš©
            face_descriptor = X[i][:128]
            physical_features = X[i][128:143]
            random_seed = X[i][143:148]
            
            # ì–¼êµ´ descriptorì— ë…¸ì´ì¦ˆ ì¶”ê°€
            face_noise = np.random.normal(0, 0.1, 128)
            face_augmented = np.clip(face_descriptor + face_noise, -3, 3)
            
            # ë¬¼ë¦¬ì  íŠ¹ì§•ì— ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€
            physical_noise = np.random.normal(0, 0.05, 15)
            physical_augmented = np.clip(physical_features + physical_noise, 0, 1)
            
            # ëœë¤ ì‹œë“œ ì¬ìƒì„±
            random_augmented = np.random.uniform(0, 1, 5)
            
            # ì¡°í•©
            combined_augmented = np.concatenate([face_augmented, physical_augmented, random_augmented])
            
            # ìƒ‰ìƒ ë²¡í„°ì— ë…¸ì´ì¦ˆ ì¶”ê°€
            color_noise = np.random.normal(0, 0.03, 15)
            color_augmented = np.clip(y[i] + color_noise, 0, 1)
            
            X_augmented.append(combined_augmented)
            y_augmented.append(color_augmented)
    
    return np.array(X_augmented, dtype=np.float32), np.array(y_augmented, dtype=np.float32)

def create_enhanced_face_to_color_model(input_dim=148, output_dim=15):
    """í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸ ìƒì„±"""
    model = keras.Sequential([
        # ì…ë ¥ì¸µ: 148ì°¨ì› (descriptor 128 + íŠ¹ì§• 15 + ëœë¤ 5)
        keras.layers.Dense(128, activation='relu', input_shape=(input_dim,)),
        keras.layers.BatchNormalization(),
        keras.layers.Dropout(0.3),
        
        # ì€ë‹‰ì¸µ 1
        keras.layers.Dense(64, activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.Dropout(0.2),
        
        # ì€ë‹‰ì¸µ 2
        keras.layers.Dense(32, activation='relu'),
        keras.layers.Dropout(0.1),
        
        # ì¶œë ¥ì¸µ: 15ì°¨ì› RGB ë²¡í„°
        keras.layers.Dense(output_dim, activation='sigmoid')
    ])
    
    optimizer = keras.optimizers.Adam(learning_rate=0.001)
    
    model.compile(
        optimizer=optimizer,
        loss='mse',
        metrics=['mae']
    )
    
    return model

def train_enhanced_face_to_color_model(X, y):
    """í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸ í•™ìŠµ"""
    print("ğŸ§  í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    print(f"   ì…ë ¥ ì°¨ì›: {X.shape[1]} (descriptor 128 + íŠ¹ì§• 15 + ëœë¤ 5)")
    print(f"   ì¶œë ¥ ì°¨ì›: {y.shape[1]}")
    print(f"   ì´ ìƒ˜í”Œ ìˆ˜: {len(X)}")
    
    model = create_enhanced_face_to_color_model()
    
    # Early stopping ì½œë°±
    early_stopping = keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=20,
        restore_best_weights=True,
        verbose=1
    )
    
    # í•™ìŠµë¥  ê°ì†Œ ì½œë°±
    reduce_lr = keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=10,
        min_lr=1e-7,
        verbose=1
    )
    
    # í•™ìŠµ
    history = model.fit(
        X, y,
        epochs=150,
        batch_size=32,
        validation_split=0.2,
        callbacks=[early_stopping, reduce_lr],
        verbose=1
    )
    
    # ìµœì¢… ì„±ëŠ¥ ì¶œë ¥
    final_loss = history.history['loss'][-1]
    val_loss = history.history['val_loss'][-1]
    print(f"ìµœì¢… í›ˆë ¨ ì†ì‹¤: {final_loss:.6f}")
    print(f"ìµœì¢… ê²€ì¦ ì†ì‹¤: {val_loss:.6f}")
    
    return model

def save_enhanced_face_to_color_model_as_tfjs(model):
    """í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸ì„ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_dir = os.path.join(script_dir, "..", "public", "models", "enhanced-face-to-color")
    model_dir = os.path.normpath(model_dir)
    
    # ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì‚­ì œ í›„ ì¬ìƒì„±
    import shutil
    if os.path.exists(model_dir):
        shutil.rmtree(model_dir)
    os.makedirs(model_dir, exist_ok=True)
    
    print(f"ğŸ”„ í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸ì„ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...")
    
    # 1. ëª¨ë¸ êµ¬ì¡°ë¥¼ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥
    model_topology = model.to_json()
    model_config = json.loads(model_topology)
    
    # InputLayerì˜ batch_shapeë¥¼ inputShapeë¡œ ë³€í™˜
    if 'config' in model_config and 'layers' in model_config['config']:
        for layer in model_config['config']['layers']:
            if (layer.get('module') == 'keras.layers' and 
                layer.get('class_name') == 'InputLayer'):
                layer_config = layer.get('config', {})
                if 'batch_shape' in layer_config:
                    batch_shape = layer_config['batch_shape']
                    if batch_shape and len(batch_shape) > 1:
                        layer_config['inputShape'] = batch_shape[1:]
                    del layer_config['batch_shape']
    
    # 2. ê°€ì¤‘ì¹˜ ì¶”ì¶œ ë° ì €ì¥
    weights = model.get_weights()
    weight_files = []
    
    for i, weight in enumerate(weights):
        weight_file = f"weights_{i}.bin"
        weight_path = os.path.join(model_dir, weight_file)
        weight.astype('float32').tofile(weight_path)
        weight_files.append(weight_file)
    
    # 3. ê°€ì¤‘ì¹˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±
    weights_manifest = [{
        "paths": weight_files,
        "weights": []
    }]
    
    # ê° ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ì¶”ê°€
    weight_names = []
    for layer in model.layers:
        if hasattr(layer, 'kernel'):
            weight_names.append(f"{layer.name}/kernel")
            if layer.use_bias:
                weight_names.append(f"{layer.name}/bias")
        elif hasattr(layer, 'gamma'):
            # BatchNormalization ë ˆì´ì–´
            weight_names.extend([
                f"{layer.name}/gamma",
                f"{layer.name}/beta", 
                f"{layer.name}/moving_mean",
                f"{layer.name}/moving_variance"
            ])
    
    for i, weight in enumerate(weights):
        weight_name = weight_names[i] if i < len(weight_names) else f"weight_{i}"
        weights_manifest[0]["weights"].append({
            "name": weight_name,
            "shape": list(weight.shape),
            "dtype": "float32"
        })
    
    # 4. model.json íŒŒì¼ ìƒì„±
    model_json = {
        "modelTopology": model_config,
        "weightsManifest": weights_manifest
    }
    
    with open(os.path.join(model_dir, 'model.json'), 'w') as f:
        json.dump(model_json, f, indent=2)
    
    # 5. ëª¨ë¸ ì •ë³´ ì €ì¥
    model_info = {
        'input_dim': 148,
        'output_dim': 15,
        'description': 'í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸: descriptor(128) + ë¬¼ë¦¬ì  íŠ¹ì§•(15) + ëœë¤ ì‹œë“œ(5) â†’ RGB(15)',
        'input_breakdown': {
            'face_descriptor': 128,
            'physical_features': 15,
            'random_seed': 5,
            'total': 148
        },
        'physical_features': [
            'face_aspect_ratio', 'jaw_angle', 'forehead_width', 'symmetry',
            'eye_size', 'eye_distance', 'eye_height', 'eye_angle',
            'mouth_width', 'mouth_height', 'lip_thickness',
            'nose_length', 'nose_width',
            'upper_face_ratio', 'lower_face_ratio'
        ],
        'emotions': ['happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised', 'neutral']
    }
    
    with open(os.path.join(model_dir, 'model_info.json'), 'w', encoding='utf-8') as f:
        json.dump(model_info, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸ì´ TensorFlow.js í˜•ì‹ìœ¼ë¡œ {model_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   ğŸ“ ìƒì„±ëœ íŒŒì¼: model.json, {len(weight_files)}ê°œ ê°€ì¤‘ì¹˜ íŒŒì¼, model_info.json")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘!")
    print("ğŸŒ TensorFlow.js ë¸Œë¼ìš°ì € í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    print("ğŸ“Š 148ì°¨ì› ì…ë ¥: descriptor(128) + ë¬¼ë¦¬ì  íŠ¹ì§•(15) + ëœë¤ ì‹œë“œ(5)")
    
    # ê°ì •-ìƒ‰ìƒ ë§¤í•‘ ë¡œë“œ
    print("ğŸ“Š ê°ì •-ìƒ‰ìƒ ë§¤í•‘ ë°ì´í„° ë¡œë“œ ì¤‘...")
    emotion_mapping = load_emotion_color_mapping()
    
    # í–¥ìƒëœ ë°ì´í„° ìƒì„±
    print("ğŸ”§ í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ë°ì´í„° ìƒì„± ì¤‘...")
    X, y, emotions = generate_enhanced_face_data(emotion_mapping, num_samples_per_emotion=40)
    print(f"   ìƒì„±ëœ ìƒ˜í”Œ ìˆ˜: {len(X)}")
    print(f"   ì…ë ¥ ì°¨ì›: {X.shape[1]} (descriptor 128 + íŠ¹ì§• 15 + ëœë¤ 5)")
    print(f"   ì¶œë ¥ ì°¨ì›: {y.shape[1]}")
    
    # ë°ì´í„° ì¦ê°•
    print("ğŸ”„ ë°ì´í„° ì¦ê°• ì¤‘...")
    X_augmented, y_augmented = augment_enhanced_face_data(X, y, augmentation_factor=5)
    print(f"   ì¦ê°• í›„ ìƒ˜í”Œ ìˆ˜: {len(X_augmented)}")
    
    # ëª¨ë¸ í•™ìŠµ
    print("ğŸ§  ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    model = train_enhanced_face_to_color_model(X_augmented, y_augmented)
    
    # TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("ğŸ’¾ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...")
    save_enhanced_face_to_color_model_as_tfjs(model)
    
    print("ğŸ‰ í–¥ìƒëœ ì–¼êµ´-ìƒ‰ìƒ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")
    print("ğŸŒ ì´ì œ ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
    print("   - model.json: TensorFlow.js í˜¸í™˜ ëª¨ë¸ êµ¬ì¡°")
    print("   - weights_*.bin: ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ë“¤")
    print("   - model_info.json: ëª¨ë¸ ì •ë³´ ë° íŠ¹ì§• ì„¤ëª…")

if __name__ == "__main__":
    main()
