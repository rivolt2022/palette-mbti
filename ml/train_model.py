"""
MBTI ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ ì˜ˆì¸¡ ëª¨ë¸ ìƒì„±
ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°„ë‹¨í•œ TensorFlow.js ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import LabelEncoder
import os

def hex_to_rgb_normalized(hex_color):
    """16ì§„ìˆ˜ ìƒ‰ìƒì„ 0-1 ë²”ìœ„ì˜ RGB ê°’ìœ¼ë¡œ ë³€í™˜"""
    hex_color = hex_color.lstrip('#')
    r = int(hex_color[0:2], 16) / 255.0
    g = int(hex_color[2:4], 16) / 255.0
    b = int(hex_color[4:6], 16) / 255.0
    return [r, g, b]

def load_training_data():
    """í•™ìŠµ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    data_dir = "../public/data/training-data"
    
    # ê° MBTI ì§€í‘œë³„ ë°ì´í„° ë¡œë“œ
    datasets = {}
    for indicator in ['e-i', 's-n', 't-f', 'j-p']:
        file_path = os.path.join(data_dir, f"{indicator}.json")
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            datasets[indicator] = data
    
    return datasets

def augment_color_palette(palette_rgb, noise_factor=0.05, indicator=None):
    """ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ë°ì´í„° ì¦ê°•"""
    # palette_rgbëŠ” ì´ë¯¸ í‰íƒ„í™”ëœ 15ì°¨ì› ë²¡í„° (5ê°œ ìƒ‰ìƒ Ã— 3ê°œ RGB ê°’)
    palette_array = np.array(palette_rgb)
    
    # ë…¸ì´ì¦ˆ ì¶”ê°€
    noise = np.random.normal(0, noise_factor, len(palette_array))
    augmented = np.clip(palette_array + noise, 0, 1)  # 0~1 ë²”ìœ„ë¡œ ìœ ì§€
    
    return augmented.tolist()

def prepare_data_for_training(datasets, use_augmentation=True):
    """í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
    models_data = {}
    
    for indicator, data in datasets.items():
        X = []  # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ë°ì´í„°
        y = []  # ë¼ë²¨ ë°ì´í„°
        
        for item in data:
            # 5ê°œ ìƒ‰ìƒì„ RGBë¡œ ë³€í™˜í•˜ê³  í‰íƒ„í™” (15ì°¨ì› ë²¡í„°)
            palette_rgb = []
            for color in item['palette']:
                rgb = hex_to_rgb_normalized(color)
                palette_rgb.extend(rgb)
            
            X.append(palette_rgb)
            y.append(item['label'])
            
            # ë°ì´í„° ì¦ê°• (ëª¨ë“  ëª¨ë¸ì— ì ìš©)
            if use_augmentation:
                # ëª¨ë“  ëª¨ë¸ì— 5ë°° ì¦ê°• ì ìš©
                augmentation_count = 5
                for _ in range(augmentation_count):
                    augmented_palette = augment_color_palette(palette_rgb, indicator=indicator)
                    X.append(augmented_palette)
                    y.append(item['label'])
        
        X = np.array(X, dtype=np.float32)
        
        # ë¼ë²¨ì„ ìˆ«ìë¡œ ë³€í™˜
        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)
        
        models_data[indicator] = {
            'X': X,
            'y': y_encoded,
            'label_encoder': label_encoder,
            'classes': label_encoder.classes_
        }
        
        print(f"{indicator.upper()} ë°ì´í„°: {len(X)} ìƒ˜í”Œ")
    
    return models_data

def create_simple_model(input_dim, num_classes):
    """ê°„ë‹¨í•œ ì‹ ê²½ë§ ëª¨ë¸ ìƒì„± (ë¸Œë¼ìš°ì € ìµœì í™”)"""
    model = keras.Sequential([
        keras.layers.Dense(32, activation='relu', input_shape=(input_dim,)),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(num_classes, activation='softmax')
    ])
    
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def create_improved_model(input_dim, num_classes, indicator):
    """ê°œì„ ëœ ì‹ ê²½ë§ ëª¨ë¸ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)"""
    # ëª¨ë“  ëª¨ë¸ì— ë™ì¼í•œ êµ¬ì¡° ì‚¬ìš©
    model = keras.Sequential([
        keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),
        keras.layers.BatchNormalization(),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(32, activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(num_classes, activation='softmax')
    ])
    
    # ëª¨ë“  ëª¨ë¸ì— ë™ì¼í•œ ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    optimizer = keras.optimizers.Adam(learning_rate=0.001)
    
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def train_models(models_data):
    """ê° MBTI ì§€í‘œë³„ ëª¨ë¸ í•™ìŠµ"""
    trained_models = {}
    
    for indicator, data in models_data.items():
        print(f"\n=== {indicator.upper()} ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
        
        X = data['X']
        y = data['y']
        num_classes = len(data['classes'])
        
        # ê°œì„ ëœ ëª¨ë¸ ìƒì„±
        model = create_improved_model(X.shape[1], num_classes, indicator)
        
        # ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
        print(f"ì…ë ¥ ì°¨ì›: {X.shape[1]}")
        print(f"í´ë˜ìŠ¤ ìˆ˜: {num_classes}")
        print(f"í´ë˜ìŠ¤: {data['classes']}")
        
        # Early stopping ì½œë°±
        early_stopping = keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=10,
            restore_best_weights=True,
            verbose=1
        )
        
        # í•™ìŠµë¥  ê°ì†Œ ì½œë°±
        reduce_lr = keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7,
            verbose=1
        )
        
        # í•™ìŠµ
        history = model.fit(
            X, y,
            epochs=100,  # ë” ë§ì€ ì—í¬í¬
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping, reduce_lr],
            verbose=1
        )
        
        # ì •í™•ë„ ì¶œë ¥
        final_accuracy = history.history['accuracy'][-1]
        val_accuracy = history.history['val_accuracy'][-1]
        print(f"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {final_accuracy:.4f}")
        print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {val_accuracy:.4f}")
        
        trained_models[indicator] = {
            'model': model,
            'label_encoder': data['label_encoder'],
            'classes': data['classes']
        }
    
    return trained_models

def save_models_as_tfjs(trained_models):
    """ëª¨ë¸ì„ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë¸Œë¼ìš°ì € ìµœì í™”)"""
    # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    models_dir = "../public/models"
    os.makedirs(models_dir, exist_ok=True)
    
    for indicator, model_data in trained_models.items():
        model_dir = os.path.join(models_dir, indicator)
        os.makedirs(model_dir, exist_ok=True)
        
        # ê¸°ì¡´ íŒŒì¼ë“¤ ì‚­ì œ
        import shutil
        if os.path.exists(model_dir):
            shutil.rmtree(model_dir)
        os.makedirs(model_dir, exist_ok=True)
        
        print(f"ğŸ”„ {indicator} ëª¨ë¸ì„ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...")
        
        # TensorFlow.js í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ëª¨ë¸ ì €ì¥
        model = model_data['model']
        
        # 1. ëª¨ë¸ êµ¬ì¡°ë¥¼ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥
        model_topology = model.to_json()
        model_config = json.loads(model_topology)
        
        # InputLayerì˜ batch_shapeë¥¼ inputShapeë¡œ ë³€í™˜
        if 'config' in model_config and 'layers' in model_config['config']:
            for layer in model_config['config']['layers']:
                if (layer.get('module') == 'keras.layers' and 
                    layer.get('class_name') == 'InputLayer'):
                    layer_config = layer.get('config', {})
                    if 'batch_shape' in layer_config:
                        batch_shape = layer_config['batch_shape']
                        if batch_shape and len(batch_shape) > 1:
                            # batch_shape [null, 15] -> inputShape [15]
                            layer_config['inputShape'] = batch_shape[1:]
                        # batch_shape ì œê±°
                        del layer_config['batch_shape']
        
        # 2. ê°€ì¤‘ì¹˜ ì¶”ì¶œ ë° ì €ì¥
        weights = model.get_weights()
        weight_files = []
        
        for i, weight in enumerate(weights):
            weight_file = f"weights_{i}.bin"
            weight_path = os.path.join(model_dir, weight_file)
            
            # ê°€ì¤‘ì¹˜ë¥¼ float32ë¡œ ì €ì¥
            weight.astype('float32').tofile(weight_path)
            weight_files.append(weight_file)
        
        # 3. ê°€ì¤‘ì¹˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± (TensorFlow.js í˜¸í™˜ í˜•ì‹)
        weights_manifest = [{
            "paths": weight_files,
            "weights": []
        }]
        
        # ê° ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ì¶”ê°€ (ì‹¤ì œ ë ˆì´ì–´ ì´ë¦„ ì‚¬ìš©)
        weight_names = []
        for layer in model.layers:
            if hasattr(layer, 'kernel'):
                weight_names.append(f"{layer.name}/kernel")
                if layer.use_bias:
                    weight_names.append(f"{layer.name}/bias")
            elif hasattr(layer, 'gamma'):
                # BatchNormalization ë ˆì´ì–´
                weight_names.extend([
                    f"{layer.name}/gamma",
                    f"{layer.name}/beta", 
                    f"{layer.name}/moving_mean",
                    f"{layer.name}/moving_variance"
                ])
        
        for i, weight in enumerate(weights):
            weight_name = weight_names[i] if i < len(weight_names) else f"weight_{i}"
            weights_manifest[0]["weights"].append({
                "name": weight_name,
                "shape": list(weight.shape),
                "dtype": "float32"
            })
        
        # 4. model.json íŒŒì¼ ìƒì„± (TensorFlow.js í˜¸í™˜ í˜•ì‹)
        model_json = {
            "modelTopology": model_config,
            "weightsManifest": weights_manifest
        }
        
        with open(os.path.join(model_dir, 'model.json'), 'w') as f:
            json.dump(model_json, f, indent=2)
        
        # 4. ë¼ë²¨ ì •ë³´ ì €ì¥
        label_info = {
            'classes': model_data['classes'].tolist(),
            'indicator': indicator
        }
        
        with open(os.path.join(model_dir, 'labels.json'), 'w', encoding='utf-8') as f:
            json.dump(label_info, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… {indicator} ëª¨ë¸ì´ TensorFlow.js í˜•ì‹ìœ¼ë¡œ {model_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"   ğŸ“ ìƒì„±ëœ íŒŒì¼: model.json, {len(weight_files)}ê°œ ê°€ì¤‘ì¹˜ íŒŒì¼, labels.json")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ MBTI ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘!")
    print("ğŸŒ TensorFlow.js ë¸Œë¼ìš°ì € í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š í•™ìŠµ ë°ì´í„° ë¡œë“œ ì¤‘...")
    datasets = load_training_data()
    
    # ë°ì´í„° ì „ì²˜ë¦¬ (ë°ì´í„° ì¦ê°• í¬í•¨)
    print("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°• ì¤‘...")
    models_data = prepare_data_for_training(datasets, use_augmentation=True)
    
    # ëª¨ë¸ í•™ìŠµ
    print("ğŸ§  ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    trained_models = train_models(models_data)
    
    # TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("ğŸ’¾ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...")
    save_models_as_tfjs(trained_models)
    
    print("ğŸ‰ ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")
    print("ğŸŒ ì´ì œ ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
    print("   - model.json: TensorFlow.js í˜¸í™˜ ëª¨ë¸ êµ¬ì¡°")
    print("   - weights_*.bin: ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ë“¤")
    print("   - labels.json: ë¼ë²¨ ì •ë³´")

if __name__ == "__main__":
    main()
