python train_model.py
2025-10-14 19:12:58.009059: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-10-14 19:13:00.081065: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
🚀 MBTI 컬러 팔레트 모델 학습 시작!
🌐 TensorFlow.js 브라우저 호환 형식으로 저장
📊 학습 데이터 로드 중...
🔧 데이터 전처리 및 증강 중...
E-I 데이터: 8000 샘플
S-N 데이터: 8000 샘플
T-F 데이터: 8000 샘플
J-P 데이터: 12000 샘플
🧠 모델 학습 시작...

=== E-I 모델 학습 시작 ===
C:\Users\PC\miniconda3\Lib\site-packages\keras\src\layers\core\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-10-14 19:13:01.873289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
입력 차원: 15
클래스 수: 2
클래스: ['E' 'I']
Epoch 1/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.9645 - loss: 0.1178 - val_accuracy: 1.0000 - val_loss: 0.0571 - learning_rate: 0.0010
Epoch 2/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 952us/step - accuracy: 0.9989 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 4.0443e-04 - learning_rate: 0.0010
Epoch 3/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 922us/step - accuracy: 0.9998 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 2.0338e-05 - learning_rate: 0.0010
Epoch 4/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 8.6864e-06 - learning_rate: 0.0010
Epoch 5/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 907us/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 2.0349e-06 - learning_rate: 0.0010
Epoch 6/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 955us/step - accuracy: 0.9998 - loss: 9.8628e-04 - val_accuracy: 1.0000 - val_loss: 1.0023e-06 - learning_rate: 0.0010
Epoch 7/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9997 - loss: 9.6038e-04 - val_accuracy: 1.0000 - val_loss: 1.2069e-06 - learning_rate: 0.0010
Epoch 8/100
142/200 ━━━━━━━━━━━━━━━━━━━━ 0s 714us/step - accuracy: 0.9996 - loss: 0.0011    
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 984us/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 3.2477e-07 - learning_rate: 0.0010
Epoch 9/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 931us/step - accuracy: 1.0000 - loss: 5.0288e-04 - val_accuracy: 1.0000 - val_loss: 2.5704e-07 - learning_rate: 5.0000e-04
Epoch 10/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 923us/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 6.0268e-07 - learning_rate: 5.0000e-04
Epoch 11/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 947us/step - accuracy: 0.9998 - loss: 4.5221e-04 - val_accuracy: 1.0000 - val_loss: 2.7247e-07 - learning_rate: 5.0000e-04
Epoch 11: early stopping
Restoring model weights from the end of the best epoch: 1.
최종 훈련 정확도: 0.9998
최종 검증 정확도: 1.0000

=== S-N 모델 학습 시작 ===
입력 차원: 15
클래스 수: 2
클래스: ['N' 'S']
Epoch 1/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.8144 - loss: 0.4617 - val_accuracy: 0.2763 - val_loss: 1.1059 - learning_rate: 0.0010
Epoch 2/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 959us/step - accuracy: 0.9330 - loss: 0.1798 - val_accuracy: 0.7962 - val_loss: 0.4347 - learning_rate: 0.0010
Epoch 3/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 948us/step - accuracy: 0.9466 - loss: 0.1483 - val_accuracy: 0.9262 - val_loss: 0.1966 - learning_rate: 0.0010
Epoch 4/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 952us/step - accuracy: 0.9573 - loss: 0.1127 - val_accuracy: 0.9488 - val_loss: 0.1378 - learning_rate: 0.0010
Epoch 5/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 920us/step - accuracy: 0.9595 - loss: 0.1090 - val_accuracy: 0.9575 - val_loss: 0.1073 - learning_rate: 0.0010
Epoch 6/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 970us/step - accuracy: 0.9706 - loss: 0.0900 - val_accuracy: 0.9394 - val_loss: 0.1751 - learning_rate: 0.0010
Epoch 7/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 931us/step - accuracy: 0.9706 - loss: 0.0898 - val_accuracy: 0.9413 - val_loss: 0.1629 - learning_rate: 0.0010
Epoch 8/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 921us/step - accuracy: 0.9686 - loss: 0.0876 - val_accuracy: 0.9500 - val_loss: 0.1518 - learning_rate: 0.0010
Epoch 9/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 928us/step - accuracy: 0.9691 - loss: 0.0914 - val_accuracy: 0.9494 - val_loss: 0.1413 - learning_rate: 0.0010
Epoch 10/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9716 - loss: 0.0808 - val_accuracy: 0.9681 - val_loss: 0.0841 - learning_rate: 0.0010
Epoch 11/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 957us/step - accuracy: 0.9742 - loss: 0.0751 - val_accuracy: 0.9569 - val_loss: 0.1174 - learning_rate: 0.0010
Epoch 12/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 921us/step - accuracy: 0.9744 - loss: 0.0733 - val_accuracy: 0.9425 - val_loss: 0.1855 - learning_rate: 0.0010
Epoch 13/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 936us/step - accuracy: 0.9773 - loss: 0.0679 - val_accuracy: 0.9688 - val_loss: 0.1065 - learning_rate: 0.0010
Epoch 14/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 926us/step - accuracy: 0.9769 - loss: 0.0688 - val_accuracy: 0.9425 - val_loss: 0.1879 - learning_rate: 0.0010
Epoch 15/100
152/200 ━━━━━━━━━━━━━━━━━━━━ 0s 665us/step - accuracy: 0.9821 - loss: 0.0540
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 971us/step - accuracy: 0.9773 - loss: 0.0656 - val_accuracy: 0.9656 - val_loss: 0.1310 - learning_rate: 0.0010
Epoch 16/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 948us/step - accuracy: 0.9784 - loss: 0.0598 - val_accuracy: 0.9631 - val_loss: 0.1067 - learning_rate: 5.0000e-04
Epoch 17/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 897us/step - accuracy: 0.9797 - loss: 0.0541 - val_accuracy: 0.9575 - val_loss: 0.1442 - learning_rate: 5.0000e-04
Epoch 18/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 935us/step - accuracy: 0.9806 - loss: 0.0564 - val_accuracy: 0.9638 - val_loss: 0.1102 - learning_rate: 5.0000e-04
Epoch 19/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 936us/step - accuracy: 0.9845 - loss: 0.0474 - val_accuracy: 0.9550 - val_loss: 0.1359 - learning_rate: 5.0000e-04
Epoch 20/100
150/200 ━━━━━━━━━━━━━━━━━━━━ 0s 674us/step - accuracy: 0.9802 - loss: 0.0561
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 939us/step - accuracy: 0.9805 - loss: 0.0562 - val_accuracy: 0.9600 - val_loss: 0.1357 - learning_rate: 5.0000e-04
Epoch 21/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 939us/step - accuracy: 0.9836 - loss: 0.0522 - val_accuracy: 0.9563 - val_loss: 0.1328 - learning_rate: 2.5000e-04
Epoch 22/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 906us/step - accuracy: 0.9814 - loss: 0.0522 - val_accuracy: 0.9569 - val_loss: 0.1450 - learning_rate: 2.5000e-04
Epoch 23/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 891us/step - accuracy: 0.9828 - loss: 0.0529 - val_accuracy: 0.9581 - val_loss: 0.1384 - learning_rate: 2.5000e-04
Epoch 23: early stopping
Restoring model weights from the end of the best epoch: 13.
최종 훈련 정확도: 0.9828
최종 검증 정확도: 0.9581

=== T-F 모델 학습 시작 ===
입력 차원: 15
클래스 수: 2
클래스: ['F' 'T']
Epoch 1/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.8889 - loss: 0.2614 - val_accuracy: 1.0000 - val_loss: 0.0517 - learning_rate: 0.0010
Epoch 2/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 925us/step - accuracy: 0.9823 - loss: 0.0577 - val_accuracy: 1.0000 - val_loss: 0.0043 - learning_rate: 0.0010
Epoch 3/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 952us/step - accuracy: 0.9858 - loss: 0.0450 - val_accuracy: 1.0000 - val_loss: 0.0019 - learning_rate: 0.0010
Epoch 4/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 955us/step - accuracy: 0.9869 - loss: 0.0396 - val_accuracy: 1.0000 - val_loss: 9.0204e-04 - learning_rate: 0.0010
Epoch 5/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 989us/step - accuracy: 0.9870 - loss: 0.0427 - val_accuracy: 1.0000 - val_loss: 0.0027 - learning_rate: 0.0010
Epoch 6/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 934us/step - accuracy: 0.9884 - loss: 0.0303 - val_accuracy: 0.9994 - val_loss: 0.0024 - learning_rate: 0.0010
Epoch 7/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 892us/step - accuracy: 0.9906 - loss: 0.0279 - val_accuracy: 0.9987 - val_loss: 0.0028 - learning_rate: 0.0010
Epoch 8/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 933us/step - accuracy: 0.9872 - loss: 0.0396 - val_accuracy: 0.9975 - val_loss: 0.0074 - learning_rate: 0.0010
Epoch 9/100
149/200 ━━━━━━━━━━━━━━━━━━━━ 0s 678us/step - accuracy: 0.9937 - loss: 0.0191
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 941us/step - accuracy: 0.9920 - loss: 0.0247 - val_accuracy: 0.9994 - val_loss: 0.0018 - learning_rate: 0.0010
Epoch 10/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 936us/step - accuracy: 0.9905 - loss: 0.0280 - val_accuracy: 0.9994 - val_loss: 0.0035 - learning_rate: 5.0000e-04
Epoch 11/100
200/200 ━━━━━━━━━━━━━━━━━━━━ 0s 922us/step - accuracy: 0.9916 - loss: 0.0290 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 5.0000e-04
Epoch 11: early stopping
Restoring model weights from the end of the best epoch: 1.
최종 훈련 정확도: 0.9916
최종 검증 정확도: 1.0000

=== J-P 모델 학습 시작 ===
입력 차원: 15
클래스 수: 2
클래스: ['J' 'P']
Epoch 1/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.8168 - loss: 0.4361 - val_accuracy: 0.4150 - val_loss: 1.0754 - learning_rate: 0.0020
Epoch 2/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9384 - loss: 0.1739 - val_accuracy: 0.9575 - val_loss: 0.1146 - learning_rate: 0.0020
Epoch 3/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 990us/step - accuracy: 0.9540 - loss: 0.1358 - val_accuracy: 0.9675 - val_loss: 0.1123 - learning_rate: 0.0020
Epoch 4/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 995us/step - accuracy: 0.9624 - loss: 0.1120 - val_accuracy: 0.9833 - val_loss: 0.0539 - learning_rate: 0.0020
Epoch 5/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 959us/step - accuracy: 0.9652 - loss: 0.1012 - val_accuracy: 0.9671 - val_loss: 0.0799 - learning_rate: 0.0020
Epoch 6/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 990us/step - accuracy: 0.9670 - loss: 0.0977 - val_accuracy: 0.9733 - val_loss: 0.0717 - learning_rate: 0.0020
Epoch 7/100
265/300 ━━━━━━━━━━━━━━━━━━━━ 0s 765us/step - accuracy: 0.9683 - loss: 0.0909
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 998us/step - accuracy: 0.9692 - loss: 0.0912 - val_accuracy: 0.9717 - val_loss: 0.0847 - learning_rate: 0.0020
Epoch 8/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 972us/step - accuracy: 0.9729 - loss: 0.0791 - val_accuracy: 0.9796 - val_loss: 0.0535 - learning_rate: 6.0000e-04
Epoch 9/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 958us/step - accuracy: 0.9749 - loss: 0.0737 - val_accuracy: 0.9808 - val_loss: 0.0535 - learning_rate: 6.0000e-04
Epoch 10/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 964us/step - accuracy: 0.9764 - loss: 0.0670 - val_accuracy: 0.9821 - val_loss: 0.0522 - learning_rate: 6.0000e-04
Epoch 11/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9790 - loss: 0.0669 - val_accuracy: 0.9762 - val_loss: 0.0670 - learning_rate: 6.0000e-04
Epoch 12/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9781 - loss: 0.0678 - val_accuracy: 0.9812 - val_loss: 0.0462 - learning_rate: 6.0000e-04
Epoch 13/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9791 - loss: 0.0682 - val_accuracy: 0.9767 - val_loss: 0.0619 - learning_rate: 6.0000e-04
Epoch 14/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9776 - loss: 0.0691 - val_accuracy: 0.9792 - val_loss: 0.0477 - learning_rate: 6.0000e-04
Epoch 15/100
255/300 ━━━━━━━━━━━━━━━━━━━━ 0s 795us/step - accuracy: 0.9783 - loss: 0.0637
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00018000000854954124.
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9805 - loss: 0.0591 - val_accuracy: 0.9846 - val_loss: 0.0470 - learning_rate: 6.0000e-04
Epoch 16/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9802 - loss: 0.0578 - val_accuracy: 0.9771 - val_loss: 0.0641 - learning_rate: 1.8000e-04
Epoch 17/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9784 - loss: 0.0674 - val_accuracy: 0.9771 - val_loss: 0.0617 - learning_rate: 1.8000e-04
Epoch 18/100
263/300 ━━━━━━━━━━━━━━━━━━━━ 0s 770us/step - accuracy: 0.9839 - loss: 0.0583
Epoch 18: ReduceLROnPlateau reducing learning rate to 5.400000081863254e-05.
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9823 - loss: 0.0592 - val_accuracy: 0.9808 - val_loss: 0.0521 - learning_rate: 1.8000e-04
Epoch 19/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 979us/step - accuracy: 0.9795 - loss: 0.0594 - val_accuracy: 0.9808 - val_loss: 0.0539 - learning_rate: 5.4000e-05
Epoch 20/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 959us/step - accuracy: 0.9786 - loss: 0.0676 - val_accuracy: 0.9787 - val_loss: 0.0561 - learning_rate: 5.4000e-05
Epoch 21/100
274/300 ━━━━━━━━━━━━━━━━━━━━ 0s 738us/step - accuracy: 0.9835 - loss: 0.0536
Epoch 21: ReduceLROnPlateau reducing learning rate to 1.6200000027311033e-05.
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 954us/step - accuracy: 0.9808 - loss: 0.0597 - val_accuracy: 0.9796 - val_loss: 0.0556 - learning_rate: 5.4000e-05
Epoch 22/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9810 - loss: 0.0609 - val_accuracy: 0.9800 - val_loss: 0.0546 - learning_rate: 1.6200e-05
Epoch 23/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 993us/step - accuracy: 0.9803 - loss: 0.0630 - val_accuracy: 0.9783 - val_loss: 0.0567 - learning_rate: 1.6200e-05
Epoch 24/100
269/300 ━━━━━━━━━━━━━━━━━━━━ 0s 754us/step - accuracy: 0.9821 - loss: 0.0553
Epoch 24: ReduceLROnPlateau reducing learning rate to 4.859999899053946e-06.
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 974us/step - accuracy: 0.9790 - loss: 0.0636 - val_accuracy: 0.9804 - val_loss: 0.0555 - learning_rate: 1.6200e-05
Epoch 25/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 994us/step - accuracy: 0.9811 - loss: 0.0548 - val_accuracy: 0.9812 - val_loss: 0.0525 - learning_rate: 4.8600e-06
Epoch 26/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9829 - loss: 0.0554 - val_accuracy: 0.9800 - val_loss: 0.0545 - learning_rate: 4.8600e-06
Epoch 27/100
262/300 ━━━━━━━━━━━━━━━━━━━━ 0s 770us/step - accuracy: 0.9818 - loss: 0.0525
Epoch 27: ReduceLROnPlateau reducing learning rate to 1.4579999970010249e-06.
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 996us/step - accuracy: 0.9807 - loss: 0.0577 - val_accuracy: 0.9825 - val_loss: 0.0512 - learning_rate: 4.8600e-06
Epoch 28/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 987us/step - accuracy: 0.9826 - loss: 0.0561 - val_accuracy: 0.9812 - val_loss: 0.0520 - learning_rate: 1.4580e-06
Epoch 29/100
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 988us/step - accuracy: 0.9798 - loss: 0.0575 - val_accuracy: 0.9821 - val_loss: 0.0527 - learning_rate: 1.4580e-06
Epoch 30/100
257/300 ━━━━━━━━━━━━━━━━━━━━ 0s 789us/step - accuracy: 0.9821 - loss: 0.0564
Epoch 30: ReduceLROnPlateau reducing learning rate to 4.3740001274272796e-07.
300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9810 - loss: 0.0579 - val_accuracy: 0.9804 - val_loss: 0.0537 - learning_rate: 1.4580e-06
Epoch 30: early stopping
Restoring model weights from the end of the best epoch: 15.
최종 훈련 정확도: 0.9810
최종 검증 정확도: 0.9804
💾 TensorFlow.js 형식으로 저장 중...
🔄 e-i 모델을 TensorFlow.js 형식으로 저장 중...
✅ e-i 모델이 TensorFlow.js 형식으로 ../public/models\e-i에 저장되었습니다.
   📁 생성된 파일: model.json, 16개 가중치 파일, labels.json
🔄 s-n 모델을 TensorFlow.js 형식으로 저장 중...
✅ s-n 모델이 TensorFlow.js 형식으로 ../public/models\s-n에 저장되었습니다.
   📁 생성된 파일: model.json, 16개 가중치 파일, labels.json
🔄 t-f 모델을 TensorFlow.js 형식으로 저장 중...
✅ t-f 모델이 TensorFlow.js 형식으로 ../public/models\t-f에 저장되었습니다.
   📁 생성된 파일: model.json, 16개 가중치 파일, labels.json
🔄 j-p 모델을 TensorFlow.js 형식으로 저장 중...
✅ j-p 모델이 TensorFlow.js 형식으로 ../public/models\j-p에 저장되었습니다.
   📁 생성된 파일: model.json, 22개 가중치 파일, labels.json
🎉 모든 모델 학습 및 저장 완료!
🌐 이제 브라우저에서 바로 사용할 수 있습니다!
📁 생성된 파일들:
   - model.json: TensorFlow.js 호환 모델 구조
   - weights_*.bin: 모델 가중치 파일들
   - labels.json: 라벨 정보