python train_model.py
2025-10-14 19:12:58.009059: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
C:\Users\PC\miniconda3\Lib\site-packages\google\protobuf\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.
  warnings.warn(
2025-10-14 19:13:00.081065: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ğŸš€ MBTI ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘!
ğŸŒ TensorFlow.js ë¸Œë¼ìš°ì € í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ì €ì¥
ğŸ“Š í•™ìŠµ ë°ì´í„° ë¡œë“œ ì¤‘...
ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°• ì¤‘...
E-I ë°ì´í„°: 8000 ìƒ˜í”Œ
S-N ë°ì´í„°: 8000 ìƒ˜í”Œ
T-F ë°ì´í„°: 8000 ìƒ˜í”Œ
J-P ë°ì´í„°: 12000 ìƒ˜í”Œ
ğŸ§  ëª¨ë¸ í•™ìŠµ ì‹œì‘...

=== E-I ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===
C:\Users\PC\miniconda3\Lib\site-packages\keras\src\layers\core\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-10-14 19:13:01.873289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ì…ë ¥ ì°¨ì›: 15
í´ë˜ìŠ¤ ìˆ˜: 2
í´ë˜ìŠ¤: ['E' 'I']
Epoch 1/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - accuracy: 0.9645 - loss: 0.1178 - val_accuracy: 1.0000 - val_loss: 0.0571 - learning_rate: 0.0010
Epoch 2/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 952us/step - accuracy: 0.9989 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 4.0443e-04 - learning_rate: 0.0010
Epoch 3/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 922us/step - accuracy: 0.9998 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 2.0338e-05 - learning_rate: 0.0010
Epoch 4/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 8.6864e-06 - learning_rate: 0.0010
Epoch 5/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 907us/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 2.0349e-06 - learning_rate: 0.0010
Epoch 6/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 955us/step - accuracy: 0.9998 - loss: 9.8628e-04 - val_accuracy: 1.0000 - val_loss: 1.0023e-06 - learning_rate: 0.0010
Epoch 7/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9997 - loss: 9.6038e-04 - val_accuracy: 1.0000 - val_loss: 1.2069e-06 - learning_rate: 0.0010
Epoch 8/100
142/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 714us/step - accuracy: 0.9996 - loss: 0.0011    
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 984us/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 3.2477e-07 - learning_rate: 0.0010
Epoch 9/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 931us/step - accuracy: 1.0000 - loss: 5.0288e-04 - val_accuracy: 1.0000 - val_loss: 2.5704e-07 - learning_rate: 5.0000e-04
Epoch 10/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 923us/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 6.0268e-07 - learning_rate: 5.0000e-04
Epoch 11/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 947us/step - accuracy: 0.9998 - loss: 4.5221e-04 - val_accuracy: 1.0000 - val_loss: 2.7247e-07 - learning_rate: 5.0000e-04
Epoch 11: early stopping
Restoring model weights from the end of the best epoch: 1.
ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9998
ìµœì¢… ê²€ì¦ ì •í™•ë„: 1.0000

=== S-N ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===
ì…ë ¥ ì°¨ì›: 15
í´ë˜ìŠ¤ ìˆ˜: 2
í´ë˜ìŠ¤: ['N' 'S']
Epoch 1/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - accuracy: 0.8144 - loss: 0.4617 - val_accuracy: 0.2763 - val_loss: 1.1059 - learning_rate: 0.0010
Epoch 2/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 959us/step - accuracy: 0.9330 - loss: 0.1798 - val_accuracy: 0.7962 - val_loss: 0.4347 - learning_rate: 0.0010
Epoch 3/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 948us/step - accuracy: 0.9466 - loss: 0.1483 - val_accuracy: 0.9262 - val_loss: 0.1966 - learning_rate: 0.0010
Epoch 4/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 952us/step - accuracy: 0.9573 - loss: 0.1127 - val_accuracy: 0.9488 - val_loss: 0.1378 - learning_rate: 0.0010
Epoch 5/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 920us/step - accuracy: 0.9595 - loss: 0.1090 - val_accuracy: 0.9575 - val_loss: 0.1073 - learning_rate: 0.0010
Epoch 6/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 970us/step - accuracy: 0.9706 - loss: 0.0900 - val_accuracy: 0.9394 - val_loss: 0.1751 - learning_rate: 0.0010
Epoch 7/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 931us/step - accuracy: 0.9706 - loss: 0.0898 - val_accuracy: 0.9413 - val_loss: 0.1629 - learning_rate: 0.0010
Epoch 8/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 921us/step - accuracy: 0.9686 - loss: 0.0876 - val_accuracy: 0.9500 - val_loss: 0.1518 - learning_rate: 0.0010
Epoch 9/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 928us/step - accuracy: 0.9691 - loss: 0.0914 - val_accuracy: 0.9494 - val_loss: 0.1413 - learning_rate: 0.0010
Epoch 10/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9716 - loss: 0.0808 - val_accuracy: 0.9681 - val_loss: 0.0841 - learning_rate: 0.0010
Epoch 11/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 957us/step - accuracy: 0.9742 - loss: 0.0751 - val_accuracy: 0.9569 - val_loss: 0.1174 - learning_rate: 0.0010
Epoch 12/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 921us/step - accuracy: 0.9744 - loss: 0.0733 - val_accuracy: 0.9425 - val_loss: 0.1855 - learning_rate: 0.0010
Epoch 13/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 936us/step - accuracy: 0.9773 - loss: 0.0679 - val_accuracy: 0.9688 - val_loss: 0.1065 - learning_rate: 0.0010
Epoch 14/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 926us/step - accuracy: 0.9769 - loss: 0.0688 - val_accuracy: 0.9425 - val_loss: 0.1879 - learning_rate: 0.0010
Epoch 15/100
152/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 665us/step - accuracy: 0.9821 - loss: 0.0540
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 971us/step - accuracy: 0.9773 - loss: 0.0656 - val_accuracy: 0.9656 - val_loss: 0.1310 - learning_rate: 0.0010
Epoch 16/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 948us/step - accuracy: 0.9784 - loss: 0.0598 - val_accuracy: 0.9631 - val_loss: 0.1067 - learning_rate: 5.0000e-04
Epoch 17/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 897us/step - accuracy: 0.9797 - loss: 0.0541 - val_accuracy: 0.9575 - val_loss: 0.1442 - learning_rate: 5.0000e-04
Epoch 18/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 935us/step - accuracy: 0.9806 - loss: 0.0564 - val_accuracy: 0.9638 - val_loss: 0.1102 - learning_rate: 5.0000e-04
Epoch 19/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 936us/step - accuracy: 0.9845 - loss: 0.0474 - val_accuracy: 0.9550 - val_loss: 0.1359 - learning_rate: 5.0000e-04
Epoch 20/100
150/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 674us/step - accuracy: 0.9802 - loss: 0.0561
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 939us/step - accuracy: 0.9805 - loss: 0.0562 - val_accuracy: 0.9600 - val_loss: 0.1357 - learning_rate: 5.0000e-04
Epoch 21/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 939us/step - accuracy: 0.9836 - loss: 0.0522 - val_accuracy: 0.9563 - val_loss: 0.1328 - learning_rate: 2.5000e-04
Epoch 22/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 906us/step - accuracy: 0.9814 - loss: 0.0522 - val_accuracy: 0.9569 - val_loss: 0.1450 - learning_rate: 2.5000e-04
Epoch 23/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 891us/step - accuracy: 0.9828 - loss: 0.0529 - val_accuracy: 0.9581 - val_loss: 0.1384 - learning_rate: 2.5000e-04
Epoch 23: early stopping
Restoring model weights from the end of the best epoch: 13.
ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9828
ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.9581

=== T-F ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===
ì…ë ¥ ì°¨ì›: 15
í´ë˜ìŠ¤ ìˆ˜: 2
í´ë˜ìŠ¤: ['F' 'T']
Epoch 1/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - accuracy: 0.8889 - loss: 0.2614 - val_accuracy: 1.0000 - val_loss: 0.0517 - learning_rate: 0.0010
Epoch 2/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 925us/step - accuracy: 0.9823 - loss: 0.0577 - val_accuracy: 1.0000 - val_loss: 0.0043 - learning_rate: 0.0010
Epoch 3/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 952us/step - accuracy: 0.9858 - loss: 0.0450 - val_accuracy: 1.0000 - val_loss: 0.0019 - learning_rate: 0.0010
Epoch 4/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 955us/step - accuracy: 0.9869 - loss: 0.0396 - val_accuracy: 1.0000 - val_loss: 9.0204e-04 - learning_rate: 0.0010
Epoch 5/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 989us/step - accuracy: 0.9870 - loss: 0.0427 - val_accuracy: 1.0000 - val_loss: 0.0027 - learning_rate: 0.0010
Epoch 6/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 934us/step - accuracy: 0.9884 - loss: 0.0303 - val_accuracy: 0.9994 - val_loss: 0.0024 - learning_rate: 0.0010
Epoch 7/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 892us/step - accuracy: 0.9906 - loss: 0.0279 - val_accuracy: 0.9987 - val_loss: 0.0028 - learning_rate: 0.0010
Epoch 8/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 933us/step - accuracy: 0.9872 - loss: 0.0396 - val_accuracy: 0.9975 - val_loss: 0.0074 - learning_rate: 0.0010
Epoch 9/100
149/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 678us/step - accuracy: 0.9937 - loss: 0.0191
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 941us/step - accuracy: 0.9920 - loss: 0.0247 - val_accuracy: 0.9994 - val_loss: 0.0018 - learning_rate: 0.0010
Epoch 10/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 936us/step - accuracy: 0.9905 - loss: 0.0280 - val_accuracy: 0.9994 - val_loss: 0.0035 - learning_rate: 5.0000e-04
Epoch 11/100
200/200 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 922us/step - accuracy: 0.9916 - loss: 0.0290 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 5.0000e-04
Epoch 11: early stopping
Restoring model weights from the end of the best epoch: 1.
ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9916
ìµœì¢… ê²€ì¦ ì •í™•ë„: 1.0000

=== J-P ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===
ì…ë ¥ ì°¨ì›: 15
í´ë˜ìŠ¤ ìˆ˜: 2
í´ë˜ìŠ¤: ['J' 'P']
Epoch 1/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - accuracy: 0.8168 - loss: 0.4361 - val_accuracy: 0.4150 - val_loss: 1.0754 - learning_rate: 0.0020
Epoch 2/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9384 - loss: 0.1739 - val_accuracy: 0.9575 - val_loss: 0.1146 - learning_rate: 0.0020
Epoch 3/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 990us/step - accuracy: 0.9540 - loss: 0.1358 - val_accuracy: 0.9675 - val_loss: 0.1123 - learning_rate: 0.0020
Epoch 4/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 995us/step - accuracy: 0.9624 - loss: 0.1120 - val_accuracy: 0.9833 - val_loss: 0.0539 - learning_rate: 0.0020
Epoch 5/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 959us/step - accuracy: 0.9652 - loss: 0.1012 - val_accuracy: 0.9671 - val_loss: 0.0799 - learning_rate: 0.0020
Epoch 6/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 990us/step - accuracy: 0.9670 - loss: 0.0977 - val_accuracy: 0.9733 - val_loss: 0.0717 - learning_rate: 0.0020
Epoch 7/100
265/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 765us/step - accuracy: 0.9683 - loss: 0.0909
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 998us/step - accuracy: 0.9692 - loss: 0.0912 - val_accuracy: 0.9717 - val_loss: 0.0847 - learning_rate: 0.0020
Epoch 8/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 972us/step - accuracy: 0.9729 - loss: 0.0791 - val_accuracy: 0.9796 - val_loss: 0.0535 - learning_rate: 6.0000e-04
Epoch 9/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 958us/step - accuracy: 0.9749 - loss: 0.0737 - val_accuracy: 0.9808 - val_loss: 0.0535 - learning_rate: 6.0000e-04
Epoch 10/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 964us/step - accuracy: 0.9764 - loss: 0.0670 - val_accuracy: 0.9821 - val_loss: 0.0522 - learning_rate: 6.0000e-04
Epoch 11/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9790 - loss: 0.0669 - val_accuracy: 0.9762 - val_loss: 0.0670 - learning_rate: 6.0000e-04
Epoch 12/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9781 - loss: 0.0678 - val_accuracy: 0.9812 - val_loss: 0.0462 - learning_rate: 6.0000e-04
Epoch 13/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9791 - loss: 0.0682 - val_accuracy: 0.9767 - val_loss: 0.0619 - learning_rate: 6.0000e-04
Epoch 14/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9776 - loss: 0.0691 - val_accuracy: 0.9792 - val_loss: 0.0477 - learning_rate: 6.0000e-04
Epoch 15/100
255/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 795us/step - accuracy: 0.9783 - loss: 0.0637
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00018000000854954124.
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9805 - loss: 0.0591 - val_accuracy: 0.9846 - val_loss: 0.0470 - learning_rate: 6.0000e-04
Epoch 16/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9802 - loss: 0.0578 - val_accuracy: 0.9771 - val_loss: 0.0641 - learning_rate: 1.8000e-04
Epoch 17/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9784 - loss: 0.0674 - val_accuracy: 0.9771 - val_loss: 0.0617 - learning_rate: 1.8000e-04
Epoch 18/100
263/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 770us/step - accuracy: 0.9839 - loss: 0.0583
Epoch 18: ReduceLROnPlateau reducing learning rate to 5.400000081863254e-05.
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9823 - loss: 0.0592 - val_accuracy: 0.9808 - val_loss: 0.0521 - learning_rate: 1.8000e-04
Epoch 19/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 979us/step - accuracy: 0.9795 - loss: 0.0594 - val_accuracy: 0.9808 - val_loss: 0.0539 - learning_rate: 5.4000e-05
Epoch 20/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 959us/step - accuracy: 0.9786 - loss: 0.0676 - val_accuracy: 0.9787 - val_loss: 0.0561 - learning_rate: 5.4000e-05
Epoch 21/100
274/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 738us/step - accuracy: 0.9835 - loss: 0.0536
Epoch 21: ReduceLROnPlateau reducing learning rate to 1.6200000027311033e-05.
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 954us/step - accuracy: 0.9808 - loss: 0.0597 - val_accuracy: 0.9796 - val_loss: 0.0556 - learning_rate: 5.4000e-05
Epoch 22/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9810 - loss: 0.0609 - val_accuracy: 0.9800 - val_loss: 0.0546 - learning_rate: 1.6200e-05
Epoch 23/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 993us/step - accuracy: 0.9803 - loss: 0.0630 - val_accuracy: 0.9783 - val_loss: 0.0567 - learning_rate: 1.6200e-05
Epoch 24/100
269/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 754us/step - accuracy: 0.9821 - loss: 0.0553
Epoch 24: ReduceLROnPlateau reducing learning rate to 4.859999899053946e-06.
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 974us/step - accuracy: 0.9790 - loss: 0.0636 - val_accuracy: 0.9804 - val_loss: 0.0555 - learning_rate: 1.6200e-05
Epoch 25/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 994us/step - accuracy: 0.9811 - loss: 0.0548 - val_accuracy: 0.9812 - val_loss: 0.0525 - learning_rate: 4.8600e-06
Epoch 26/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9829 - loss: 0.0554 - val_accuracy: 0.9800 - val_loss: 0.0545 - learning_rate: 4.8600e-06
Epoch 27/100
262/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 770us/step - accuracy: 0.9818 - loss: 0.0525
Epoch 27: ReduceLROnPlateau reducing learning rate to 1.4579999970010249e-06.
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 996us/step - accuracy: 0.9807 - loss: 0.0577 - val_accuracy: 0.9825 - val_loss: 0.0512 - learning_rate: 4.8600e-06
Epoch 28/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 987us/step - accuracy: 0.9826 - loss: 0.0561 - val_accuracy: 0.9812 - val_loss: 0.0520 - learning_rate: 1.4580e-06
Epoch 29/100
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 988us/step - accuracy: 0.9798 - loss: 0.0575 - val_accuracy: 0.9821 - val_loss: 0.0527 - learning_rate: 1.4580e-06
Epoch 30/100
257/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 789us/step - accuracy: 0.9821 - loss: 0.0564
Epoch 30: ReduceLROnPlateau reducing learning rate to 4.3740001274272796e-07.
300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 1ms/step - accuracy: 0.9810 - loss: 0.0579 - val_accuracy: 0.9804 - val_loss: 0.0537 - learning_rate: 1.4580e-06
Epoch 30: early stopping
Restoring model weights from the end of the best epoch: 15.
ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9810
ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.9804
ğŸ’¾ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...
ğŸ”„ e-i ëª¨ë¸ì„ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...
âœ… e-i ëª¨ë¸ì´ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ../public/models\e-iì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
   ğŸ“ ìƒì„±ëœ íŒŒì¼: model.json, 16ê°œ ê°€ì¤‘ì¹˜ íŒŒì¼, labels.json
ğŸ”„ s-n ëª¨ë¸ì„ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...
âœ… s-n ëª¨ë¸ì´ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ../public/models\s-nì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
   ğŸ“ ìƒì„±ëœ íŒŒì¼: model.json, 16ê°œ ê°€ì¤‘ì¹˜ íŒŒì¼, labels.json
ğŸ”„ t-f ëª¨ë¸ì„ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...
âœ… t-f ëª¨ë¸ì´ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ../public/models\t-fì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
   ğŸ“ ìƒì„±ëœ íŒŒì¼: model.json, 16ê°œ ê°€ì¤‘ì¹˜ íŒŒì¼, labels.json
ğŸ”„ j-p ëª¨ë¸ì„ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì¤‘...
âœ… j-p ëª¨ë¸ì´ TensorFlow.js í˜•ì‹ìœ¼ë¡œ ../public/models\j-pì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
   ğŸ“ ìƒì„±ëœ íŒŒì¼: model.json, 22ê°œ ê°€ì¤‘ì¹˜ íŒŒì¼, labels.json
ğŸ‰ ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!
ğŸŒ ì´ì œ ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:
   - model.json: TensorFlow.js í˜¸í™˜ ëª¨ë¸ êµ¬ì¡°
   - weights_*.bin: ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ë“¤
   - labels.json: ë¼ë²¨ ì •ë³´